{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEGAN을 이용한 이미지생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****라이브러리 읽어들이기****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 71,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1388,
     "status": "ok",
     "timestamp": 1516713481299,
     "user": {
      "displayName": "Mitsuhisa Ohta",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "107586005588721640993"
     },
     "user_tz": -540
    },
    "id": "6EoENk-rlqG-",
    "outputId": "0492c79c-6897-453d-8015-b00afd1583da"
   },
   "outputs": [],
   "source": [
    "# https://drive.google.com/uc?export=download&id=1URxZOJTO38qb3v1hOT3usuAE7nTGQDnL 참조\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import losses\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Conv2D, Conv2DTranspose, Activation, Flatten, Dense, UpSampling2D, Reshape, Lambda, Input\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.preprocessing.image import img_to_array, array_to_img\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**이미지를 저장하는 함수**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imgs(path, imgs, rows, cols):\n",
    "    \"\"\"이미지를 타일 형태로 저장\n",
    "    \n",
    "    Arguments:\n",
    "        path (str): 저장할 폴더 경로\n",
    "        imgs (np.array): 저장할 이미지 리스트\n",
    "        rows (int): 타일의 세로 크기\n",
    "        cols (int): 타일의 가로 크기\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    base_width = imgs.shape[1]\n",
    "    base_height = imgs.shape[2]\n",
    "    channels = imgs.shape[3]\n",
    "    output_shape = (\n",
    "        base_height*rows,\n",
    "        base_width*cols,\n",
    "        channels\n",
    "    )\n",
    "    buffer = np.zeros(output_shape)\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            img = imgs[row*cols + col]\n",
    "            buffer[\n",
    "                row*base_height:(row + 1)*base_height,\n",
    "                col*base_width:(col + 1)*base_width\n",
    "            ] = img\n",
    "    array_to_img(buffer).save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PZhh5kkDFbXK"
   },
   "source": [
    "**이미지 데이터 읽어 들이기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 820,
     "status": "ok",
     "timestamp": 1516713490057,
     "user": {
      "displayName": "Mitsuhisa Ohta",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "107586005588721640993"
     },
     "user_tz": -540
    },
    "id": "_8jJdMsfmFQx",
    "outputId": "396afe0c-b66c-4559-ed55-c24ad3b316f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = 'data/'\n",
    "BATCH_SIZE = 24\n",
    "IMG_SHAPE = (28, 28, 3)\n",
    "\n",
    "data_gen = ImageDataGenerator(rescale=1/255.)\n",
    "train_data_generator = data_gen.flow_from_directory(\n",
    "    directory=DATA_DIR,\n",
    "    classes=['mnist'],\n",
    "    class_mode=None,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=IMG_SHAPE[:2]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sHbFoscwFiPI"
   },
   "source": [
    "**Encoder 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LLFOMimZmKR_"
   },
   "outputs": [],
   "source": [
    "def build_encoder(input_shape, z_size, n_filters, n_layers):\n",
    "    \"\"\"Encoder구축\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape (int): 이미지의 shape\n",
    "        z_size (int): 특징 공간의 차원 수\n",
    "        n_filters (int): 파일 수\n",
    "        \n",
    "    Returns:\n",
    "        model (Model): 인코더 모델 \n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            n_filters,\n",
    "            3,\n",
    "            activation='elu',\n",
    "            input_shape=input_shape,\n",
    "            padding='same'\n",
    "        )\n",
    "    )\n",
    "    model.add(Conv2D(n_filters, 3, padding='same'))\n",
    "    for i in range(2, n_layers + 1):\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                i*n_filters,\n",
    "                3,\n",
    "                activation='elu',\n",
    "                padding='same'\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "                Conv2D(\n",
    "                i*n_filters,\n",
    "                3,\n",
    "                activation='elu',\n",
    "                strides=2,\n",
    "                padding='same'\n",
    "            )\n",
    "        )\n",
    "    model.add(Conv2D(n_layers*n_filters, 3, padding='same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(z_size))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**생성자/Decoder 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "elVBPfr-mONR"
   },
   "outputs": [],
   "source": [
    "def build_decoder(output_shape, z_size, n_filters, n_layers):\n",
    "    \"\"\"Decoder 구축\n",
    "    \n",
    "    Arguments:\n",
    "        output_shape (np.array): 이미지 shape\n",
    "        z_size (int): 특징 공간의 차원 수\n",
    "        n_filters (int): 파일 수\n",
    "        n_layers (int): 레이어 수\n",
    "        \n",
    "    Returns:\n",
    "        model (Model): 디코더 모델 \n",
    "    \"\"\"\n",
    "    # UpSampling2D로 몇 배로 확대할지 계산\n",
    "    scale = 2**(n_layers - 1)\n",
    "    # 합성곱층의 처음 입력 사이즈를 scale로부터 역산\n",
    "    fc_shape = (\n",
    "        output_shape[0]//scale,\n",
    "        output_shape[1]//scale,\n",
    "        n_filters\n",
    "    )\n",
    "    # 완전연결 계층에서 필요한 사이즈를 역산\n",
    "    fc_size = fc_shape[0]*fc_shape[1]*fc_shape[2]\n",
    "    \n",
    "    model = Sequential()\n",
    "    # 완전연결 계층\n",
    "    model.add(Dense(fc_size, input_shape=(z_size,)))\n",
    "    model.add(Reshape(fc_shape))\n",
    "    \n",
    "    # 합성곱층 반복\n",
    "    for i in range(n_layers - 1):\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                n_filters,\n",
    "                3,\n",
    "                activation='elu',\n",
    "                padding='same'\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                n_filters,\n",
    "                3,\n",
    "                activation='elu',\n",
    "                padding='same'\n",
    "            )\n",
    "        )\n",
    "        model.add(UpSampling2D())\n",
    "        \n",
    "    # 마지막 층은 UpSampling2D가 불필요\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            n_filters,\n",
    "            3,\n",
    "            activation='elu',\n",
    "            padding='same'\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            n_filters,\n",
    "            3,\n",
    "            activation='elu',\n",
    "            padding='same'\n",
    "        )\n",
    "    )\n",
    "    # 출력층에서는 3채널로\n",
    "    model.add(Conv2D(3, 3, padding='same'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**생성자 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XoubtmhlmQh3"
   },
   "outputs": [],
   "source": [
    "def build_generator(img_shape, z_size, n_filters, n_layers):\n",
    "    decoder = build_decoder(\n",
    "        img_shape, z_size, n_filters, n_layers\n",
    "    )\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**구분자 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "IHMwgdgYmSwO"
   },
   "outputs": [],
   "source": [
    "def build_discriminator(img_shape, z_size, n_filters, n_layers):\n",
    "    encoder = build_encoder(\n",
    "        img_shape, z_size, n_filters, n_layers\n",
    "    )\n",
    "    decoder = build_decoder(\n",
    "        img_shape, z_size, n_filters, n_layers\n",
    "    )\n",
    "    return keras.models.Sequential((encoder, decoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**구분자의 학습용 네트워크**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RbEZL3qtmU5a"
   },
   "outputs": [],
   "source": [
    "def build_discriminator_trainer(discriminator):\n",
    "    img_shape = discriminator.input_shape[1:]\n",
    "    real_inputs = Input(img_shape)\n",
    "    fake_inputs = Input(img_shape)\n",
    "    real_outputs = discriminator(real_inputs)\n",
    "    fake_outputs = discriminator(fake_inputs)\n",
    "\n",
    "    return Model(\n",
    "        inputs=[real_inputs, fake_inputs],\n",
    "        outputs=[real_outputs, fake_outputs]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**네트워크 구축**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 731,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 915,
     "status": "ok",
     "timestamp": 1516713509294,
     "user": {
      "displayName": "Mitsuhisa Ohta",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "107586005588721640993"
     },
     "user_tz": -540
    },
    "id": "KYSTnemdmXJL",
    "outputId": "50373191-3bb8-4ee3-b587-6dd979b042b2",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 3136)              103488    \n",
      "_________________________________________________________________\n",
      "reshape_21 (Reshape)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_289 (Conv2D)          (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_290 (Conv2D)          (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_67 (UpSampling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_291 (Conv2D)          (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_292 (Conv2D)          (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_68 (UpSampling (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_293 (Conv2D)          (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_294 (Conv2D)          (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_295 (Conv2D)          (None, 28, 28, 3)         1731      \n",
      "=================================================================\n",
      "Total params: 326,787\n",
      "Trainable params: 326,787\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 3136)              103488    \n",
      "_________________________________________________________________\n",
      "reshape_22 (Reshape)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_303 (Conv2D)          (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_304 (Conv2D)          (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_69 (UpSampling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_305 (Conv2D)          (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_306 (Conv2D)          (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_70 (UpSampling (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_307 (Conv2D)          (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_308 (Conv2D)          (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_309 (Conv2D)          (None, 28, 28, 3)         1731      \n",
      "=================================================================\n",
      "Total params: 326,787\n",
      "Trainable params: 326,787\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_filters = 64  #  필터 수\n",
    "n_layers = 3 # 레이어 수\n",
    "z_size = 32  #  특징 공간의 차원\n",
    "\n",
    "generator = build_generator(\n",
    "    IMG_SHAPE, z_size, n_filters, n_layers\n",
    ")\n",
    "discriminator = build_discriminator(\n",
    "    IMG_SHAPE, z_size, n_filters, n_layers\n",
    ")\n",
    "discriminator_trainer = build_discriminator_trainer(\n",
    "    discriminator\n",
    ")\n",
    "\n",
    "generator.summary()\n",
    "# discriminator.layers[1]은 디코더를 나타냄\n",
    "discriminator.layers[1].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**손실 함수 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-i1VQ67WmeFz"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.losses import mean_absolute_error\n",
    "\n",
    "\n",
    "def build_generator_loss(discriminator):\n",
    "    # discriminator를 사용해서 손실 함수 정의\n",
    "    def loss(y_true, y_pred):\n",
    "        # y_true \n",
    "        reconst = discriminator(y_pred)\n",
    "        return mean_absolute_error(\n",
    "            reconst,\n",
    "            y_pred\n",
    "        )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**generator 컴파일**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8xlrAPpOmhAf",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 초기 학습률(Generator)\n",
    "g_lr = 0.0001\n",
    "\n",
    "generator_loss = build_generator_loss(discriminator)\n",
    "generator.compile(\n",
    "    loss=generator_loss,\n",
    "    optimizer=Adam(g_lr)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**구분자 컴파일**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FcOeTJ1qmjub"
   },
   "outputs": [],
   "source": [
    "# 초기 학습률(Discriminator)\n",
    "d_lr = 0.0001\n",
    "\n",
    "# k_var는 수치(일반 변수)\n",
    "k_var = 0.0\n",
    "# k : Keras(TensorFlow) Variable\n",
    "k = K.variable(k_var)\n",
    "discriminator_trainer.compile(\n",
    "    loss=[\n",
    "        mean_absolute_error,\n",
    "        mean_absolute_error\n",
    "    ],\n",
    "    loss_weights=[1., -k],\n",
    "    optimizer=Adam(d_lr)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**수렴 판정용 함수 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(real_loss, fake_loss, gamma):\n",
    "    return real_loss + np.abs(gamma*real_loss - fake_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_e7mjM3F4Cg"
   },
   "source": [
    "**학습 코드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 434,
     "output_extras": [
      {
       "item_id": 2
      },
      {
       "item_id": 3
      },
      {
       "item_id": 4
      }
     ]
    },
    "colab_type": "code",
    "id": "ksY4_jqFml8y",
    "outputId": "669c8c2b-c62e-4b42-f52f-e0aa03548987",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'real_loss': 0.049274366, 'measure': 0.06939699733629823, 'k': 0.020042641, 'fake_loss': 0.004514552}\n",
      "{'real_loss': 0.04165324, 'measure': 0.06225148574449122, 'k': 0.020221815, 'fake_loss': 0.004084554}\n",
      "{'real_loss': 0.04597017, 'measure': 0.06296164328232408, 'k': 0.020401094, 'fake_loss': 0.006035212}\n",
      "{'real_loss': 0.042247687, 'measure': 0.06434513765852898, 'k': 0.020588748, 'fake_loss': 0.003389097}\n",
      "{'real_loss': 0.04659957, 'measure': 0.06238659273367375, 'k': 0.02076724, 'fake_loss': 0.0055764955}\n",
      "{'real_loss': 0.045257103, 'measure': 0.06112694253679365, 'k': 0.020935792, 'fake_loss': 0.0041048005}\n",
      "{'real_loss': 0.042053778, 'measure': 0.06467423134017736, 'k': 0.021122888, 'fake_loss': 0.0035600562}\n",
      "{'real_loss': 0.046508964, 'measure': 0.060783356754109265, 'k': 0.021293417, 'fake_loss': 0.0056531336}\n",
      "{'real_loss': 0.0381217, 'measure': 0.062064941576682034, 'k': 0.021467876, 'fake_loss': 0.005105612}\n",
      "{'real_loss': 0.04963976, 'measure': 0.06320860176347196, 'k': 0.021648647, 'fake_loss': 0.0040076966}\n",
      "{'real_loss': 0.046129916, 'measure': 0.060770432162098584, 'k': 0.021824533, 'fake_loss': 0.0047170087}\n"
     ]
    }
   ],
   "source": [
    "# k의 갱신에 이용할 파라미터\n",
    "GAMMA = 0.5\n",
    "LR_K = 0.001\n",
    "\n",
    "# 반복 수. 100000～1000000 정도로 지정\n",
    "TOTAL_STEPS = 10\n",
    "\n",
    "# 모델과 확인용 생성 이미지를 저장할 폴더\n",
    "\n",
    "IMG_SAVE_DIR = 'imgs'\n",
    "# 확인용으로 4x4 개의 이미지를 생성\n",
    "IMG_SAMPLE_SHAPE = (4, 4)\n",
    "N_IMG_SAMPLES = np.prod(IMG_SAMPLE_SHAPE)\n",
    "\n",
    "\n",
    "# 저장할 폴더가 없다면 생성\n",
    "os.makedirs(IMG_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# 샘플이미지용 랜덤 시드\n",
    "sample_seeds = np.random.uniform(\n",
    "    -1, 1, (N_IMG_SAMPLES, z_size)\n",
    ")\n",
    "\n",
    "history = []\n",
    "logs = []\n",
    "\n",
    "for step, batch in enumerate(train_data_generator):\n",
    "  \n",
    "\n",
    "    # 임의의 값 생성\n",
    "    z_g = np.random.uniform(\n",
    "        -1, 1, (BATCH_SIZE, z_size)\n",
    "    )\n",
    "    z_d = np.random.uniform(\n",
    "        -1, 1, (BATCH_SIZE, z_size)\n",
    "    )\n",
    "    \n",
    "    # 생성 이미지(구분자의 학습에 이용)\n",
    "    g_pred = generator.predict(z_d)\n",
    "    \n",
    "    # 생성자를 1스텝 학습시킨다\n",
    "    generator.train_on_batch(z_g, batch)\n",
    "    # 구분자를 1스텝 학습시킨다\n",
    "    _, real_loss, fake_loss = discriminator_trainer.train_on_batch(\n",
    "            [batch, g_pred],\n",
    "            [batch, g_pred]\n",
    "    )\n",
    "\n",
    "    # k 를 갱신\n",
    "    k_var += LR_K*(GAMMA*real_loss - fake_loss)\n",
    "    K.set_value(k, k_var)\n",
    "    \n",
    "\n",
    "    # g_measure 을 계산하기 위한 loss 저장\n",
    "    history.append({\n",
    "        'real_loss': real_loss,\n",
    "        'fake_loss': fake_loss\n",
    "    })\n",
    "\n",
    "    # 10번에 1번씩 로그 표시\n",
    "    if step%10 == 0:\n",
    "        # 과거 10 번의 measure 의 평균\n",
    "        measurement = np.mean([\n",
    "            measure(\n",
    "                loss['real_loss'],\n",
    "                loss['fake_loss'],\n",
    "                GAMMA\n",
    "            )\n",
    "            for loss in history[-10:]\n",
    "        ])\n",
    "        \n",
    "        logs.append({\n",
    "            'k': K.get_value(k),\n",
    "            'measure': measurement,\n",
    "            'real_loss': real_loss,\n",
    "            'fake_loss': fake_loss\n",
    "        })\n",
    "        print(logs[-1])\n",
    "\n",
    "        # 이미지 저장  \n",
    "        img_path = '{}/generated_{}.png'.format(\n",
    "            IMG_SAVE_DIR,\n",
    "            step\n",
    "        )\n",
    "        save_imgs(\n",
    "            img_path,\n",
    "            generator.predict(sample_seeds),\n",
    "            rows=IMG_SAMPLE_SHAPE[0],\n",
    "            cols=IMG_SAMPLE_SHAPE[1]\n",
    "        )\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "BEGAN.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
